{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d011e4d3",
   "metadata": {},
   "source": [
    "# Legal Rhetorical Roles Classification using LEGAL-BERT and LEGAL-ToBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0741975",
   "metadata": {},
   "source": [
    "In these examples we show how to use LEGAL-BERT and LEGAL-ToBERT to perform rhetorical roles classification for your own legal documents."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e288bb0",
   "metadata": {},
   "source": [
    "First of all, some imports are required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb5734a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rhetorical_roles_classification import (\n",
    "    RhetoricalRolesDataset,\n",
    "    RhetoricalRolesDatasetForTransformerOverBERT\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37dd615d",
   "metadata": {},
   "source": [
    "## Load the Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f84442b",
   "metadata": {},
   "source": [
    "Our models are not stored in this repository but can be download from [here](https://drive.google.com/drive/folders/12U6XzXmWeNeYmwWG4QZNZrAffZqfMw9p?usp=sharing\n",
    "). In these exmples we use BERT and ToBERT for the English language. These are associated with some configuration info, like the maximum document length supported by ToBERT, wich must be taken into account when using it for your own purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321200b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToBERT Maximum supported document length: 386\n",
      "Label to rhetorical role mapping:\n",
      "{0: 'PREAMBLE',\n",
      " 1: 'FAC',\n",
      " 2: 'RLC',\n",
      " 3: 'ISSUE',\n",
      " 4: 'ARG_PETITIONER',\n",
      " 5: 'ARG_RESPONDENT',\n",
      " 6: 'ANALYSIS',\n",
      " 7: 'STA',\n",
      " 8: 'PRE_RELIED',\n",
      " 9: 'PRE_NOT_RELIED',\n",
      " 10: 'RATIO',\n",
      " 11: 'RPC',\n",
      " 12: 'NONE'}\n"
     ]
    }
   ],
   "source": [
    "MODELS_FOLDER = \"./models/eng\"\n",
    "\n",
    "bert, bert_config = joblib.load(\n",
    "    os.path.join(MODELS_FOLDER, \"LEGAL-BERT.joblib\")\n",
    ")\n",
    "tobert, tobert_config = joblib.load(\n",
    "    os.path.join(MODELS_FOLDER, \"LEGAL-ToBERT.joblib\")\n",
    ")\n",
    "\n",
    "print(\"ToBERT Maximum supported document length:\", tobert_config[\"max_document_length\"])\n",
    "print(\"Label to rhetorical role mapping:\")\n",
    "pprint(tobert_config[\"label2rhetRole\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5a3f7a2",
   "metadata": {},
   "source": [
    "## Prepare the Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43ebae50",
   "metadata": {},
   "source": [
    "In these examples we use the BUILD public benchmark dataset. The dataset has to be preprocessed in such a way to be usable by LEGAL-BERT and LEGAL-ToBERT. `RhetoricalRolesDataset` and `RhetoricalRolesDatasetForTransformerOverBERT` do exactly this. Specifically:\n",
    "- `RhetoricalRolesDataset` takes as input the path to a `.csv` file storing each input sentence in a `segments` column;\n",
    "- `RhetoricalRolesDatasetForTransformerOverBERT` takes as input the path to a `.json` file consisting of a list of documents. Each document must be represented as a dictionary with a `segments` key associated with the list of sentences of the document.  \n",
    "\n",
    "Some more arguments are necessary for tokenization: be sure to use the same values as the models configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a74ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"./BUILD/data\"\n",
    "\n",
    "bert_dataset = RhetoricalRolesDataset(\n",
    "    data_filepath=os.path.join(DATA_FOLDER, \"test.csv\"),\n",
    "    max_segment_length=bert_config[\"max_segment_length\"],\n",
    "    tokenizer_model_name=bert_config[\"tokenizer_model_name\"],\n",
    "    has_labels=False\n",
    ")\n",
    "tobert_dataset = RhetoricalRolesDatasetForTransformerOverBERT(\n",
    "    data_filepath=os.path.join(DATA_FOLDER, \"test.json\"),\n",
    "    max_document_length=tobert_config[\"max_document_length\"],\n",
    "    max_segment_length=tobert_config[\"max_segment_length\"],\n",
    "    tokenizer_model_name=tobert_config[\"tokenizer_model_name\"],\n",
    "    has_labels=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc1e6823",
   "metadata": {},
   "source": [
    "## Inference with LEGAL-BERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c5c1240",
   "metadata": {},
   "source": [
    "Using LEGAL-BERT for inference is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be68c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_dataloader = torch.utils.data.DataLoader(\n",
    "    bert_dataset,\n",
    "    batch_size=128\n",
    ")\n",
    "\n",
    "bert.eval()\n",
    "bert_predictions = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(bert_dataloader):\n",
    "        output = bert(data, labels=None)\n",
    "        logits = output.logits\n",
    "        bert_predictions += logits.argmax(dim=-1).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e16b1382",
   "metadata": {},
   "source": [
    "## Inference with LEGAL-ToBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "076e2989",
   "metadata": {},
   "source": [
    "Using LEGAL-ToBERT for inference is straightforward, too. The only difference is that padding sentences predictions must be filtered out from the output of the model.\n",
    "This is done by retrieving the number of sentences for each document, taking into account that padding sentences are all 0's vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tobert_dataloader = torch.utils.data.DataLoader(\n",
    "    tobert_dataset,\n",
    "    batch_size=1\n",
    ")\n",
    "\n",
    "tobert.eval()\n",
    "tobert_predictions = []\n",
    "with torch.no_grad():\n",
    "    for documents in tqdm(tobert_dataloader):\n",
    "        output = tobert(documents, labels=None)\n",
    "        logits = output.logits  # Shape: (batch_size = 1, max_document_length, num_labels)\n",
    "        n_sentences = len([sentence for sentence in documents[0] if sentence.any()])\n",
    "        tobert_predictions += logits.argmax(dim=-1).ravel().tolist()[:n_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2943b2e8",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fcac673",
   "metadata": {},
   "source": [
    "For demonstration purposes, we compute some relevant scores from BERT and ToBERT predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ce80c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT:\n",
      "\tAccuracy: 0.6561306009030914\n",
      "\tMCC: 0.5594308542642985\n",
      "ToBERT:\n",
      "\tAccuracy: 0.7846474470302188\n",
      "\tMCC: 0.7267670113883938\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_FOLDER, \"test.csv\"))\n",
    "labels = df.labels\n",
    "\n",
    "print(\"BERT:\")\n",
    "print(f\"\\tAccuracy: {accuracy_score(labels, bert_predictions)}\")\n",
    "print(f\"\\tMCC: {matthews_corrcoef(labels, bert_predictions)}\")\n",
    "\n",
    "print(\"ToBERT:\")\n",
    "print(f\"\\tAccuracy: {accuracy_score(labels, tobert_predictions)}\")\n",
    "print(f\"\\tMCC: {matthews_corrcoef(labels, tobert_predictions)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "503b4cee5d758491a5c5bfdd7aeeeb186e46ff0620f68ae22d961a7d88744c99"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
